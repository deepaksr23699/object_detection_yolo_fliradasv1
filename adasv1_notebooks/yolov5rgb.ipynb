{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.yaml created at: /home/deepaksr/project/project_assignment2/adasv1_notebooks/rgb.yaml\n"
     ]
    }
   ],
   "source": [
    "# Define paths to the train, val, and test directories\n",
    "train_images_dir = '/home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/train/rgbwithlabels/images'\n",
    "val_images_dir = '/home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/val/rgbwithlabels/images'\n",
    "test_images_dir = '/home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images'  # Optional\n",
    "\n",
    "# Path where you want to save your dataset.yaml file\n",
    "yaml_file_path = '/home/deepaksr/project/project_assignment2/adasv1_notebooks/rgb.yaml'\n",
    "\n",
    "# Number of classes and their names\n",
    "num_classes = 4\n",
    "class_names = ['person', 'bicycle', 'car', 'dog']\n",
    "\n",
    "# Create the YAML file content\n",
    "yaml_content = f\"\"\"\n",
    "# Paths to the training and validation datasets\n",
    "train: {train_images_dir}\n",
    "val: {val_images_dir}\n",
    "\n",
    "# Optional: Path to the test dataset (if you have one)\n",
    "test: {test_images_dir}\n",
    "\n",
    "# Number of classes\n",
    "nc: {num_classes}\n",
    "\n",
    "# Class names\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "\n",
    "# Write the content to the dataset.yaml file\n",
    "with open(yaml_file_path, 'w') as yaml_file:\n",
    "    yaml_file.write(yaml_content)\n",
    "\n",
    "print(f'dataset.yaml created at: {yaml_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the YAML file:\n",
      "\n",
      "# Paths to the training and validation datasets\n",
      "train: /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/train/rgbwithlabels/images\n",
      "val: /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/val/rgbwithlabels/images\n",
      "\n",
      "# Optional: Path to the test dataset (if you have one)\n",
      "test: /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images\n",
      "\n",
      "# Number of classes\n",
      "nc: 4\n",
      "\n",
      "# Class names\n",
      "names: ['person', 'bicycle', 'car', 'dog']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to your YAML file\n",
    "yaml_file_path = '/home/deepaksr/project/project_assignment2/adasv1_notebooks/rgb.yaml'  # Adjust this if needed\n",
    "\n",
    "# Read and print the contents of the YAML file\n",
    "with open(yaml_file_path, 'r') as yaml_file:\n",
    "    yaml_contents = yaml_file.read()\n",
    "\n",
    "print(\"Contents of the YAML file:\")\n",
    "print(yaml_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gitpython>=3.1.30 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (3.1.43)\n",
      "Requirement already satisfied: matplotlib>=3.3 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (3.7.5)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 7)) (1.23.5)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 8)) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=10.3.0 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 9)) (10.4.0)\n",
      "Requirement already satisfied: psutil in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 10)) (6.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 11)) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 13)) (1.10.1)\n",
      "Requirement already satisfied: thop>=0.1.1 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 14)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2.4.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 16)) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 17)) (4.66.5)\n",
      "Requirement already satisfied: ultralytics>=8.2.34 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (8.3.9)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 28)) (0.13.2)\n",
      "Requirement already satisfied: setuptools>=70.0.0 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 42)) (75.1.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from gitpython>=3.1.30->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (4.0.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (6.4.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from requests>=2.32.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from requests>=2.32.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from requests>=2.32.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from requests>=2.32.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.6.77)\n",
      "Requirement already satisfied: py-cpuinfo in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from ultralytics>=8.2.34->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (9.0.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from ultralytics>=8.2.34->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (2.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from pandas>=1.1.4->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from pandas>=1.1.4->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2024.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (5.0.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from jinja2->torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages (from sympy->torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "%pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deepaksr/project/project_assignment2/adas_v1/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd /home/deepaksr/project/project_assignment2/adas_v1/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
      "/home/deepaksr/project/project_assignment2/adas_v1/yolov5\n"
     ]
    }
   ],
   "source": [
    "# Clone YOLOv5 repository\n",
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/home/deepaksr/project/project_assignment2/adasv1_notebooks/rgb.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=21, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=0,1,2,3, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 16 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "YOLOv5 🚀 v7.0-371-g6629839d Python-3.8.20 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
      "                                                             CUDA:1 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
      "                                                             CUDA:2 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
      "                                                             CUDA:3 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "/home/deepaksr/project/project_assignment2/adas_v1/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/home/deepaksr/project/project_assignment2/adas_v1/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "WARNING ⚠️ DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\n",
      "See Multi-GPU Tutorial at https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training to get started.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/train/rgbwithlabels/images/FLIR_05639.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/train/rgbwithlabels/images/FLIR_05812.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/train/rgbwithlabels/images/FLIR_07226.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/train/rgbwithlabels/images/FLIR_07525.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/v\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/val/rgbwithlabels/images/FLIR_09042.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/val/rgbwithlabels/images/FLIR_09055.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/val/rgbwithlabels/images/FLIR_09653.jpg: 1 duplicate labels removed\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.01 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp20/labels.jpg... \n",
      "train.py:355: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp20\u001b[0m\n",
      "Starting training for 21 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "  0%|          | 0/262 [00:00<?, ?it/s]train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "       0/20      1.83G     0.1241    0.06026    0.04329        387        640:  train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "       0/20      2.21G    0.09526    0.05923    0.02211         88        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.349      0.167     0.0701     0.0178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/20      3.68G     0.0841    0.05624    0.01242        114        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.399      0.139     0.0669     0.0178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/20      3.68G    0.08053    0.05545    0.01115        121        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.424      0.182       0.12     0.0353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/20      3.68G    0.07594    0.05464    0.01012        152        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.486      0.219      0.163     0.0513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/20      3.68G    0.07255    0.05415   0.009263         70        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.521      0.203      0.177     0.0626\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/20      3.68G    0.06998    0.05358   0.008393        198        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.551      0.229      0.214     0.0793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/20      3.68G    0.06818    0.05239   0.007979        171        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844       0.55      0.257      0.242     0.0907\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/20      3.68G     0.0666    0.05178   0.007528        108        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.519      0.201      0.177     0.0678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/20      3.68G    0.06516    0.05148    0.00711         97        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.521      0.231      0.193     0.0664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/20      3.68G    0.06416    0.05062   0.006686        157        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.457      0.312      0.301      0.112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/20      3.68G    0.06314    0.05016   0.006535         97        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844       0.37      0.278      0.282      0.109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/20      3.68G    0.06211    0.05005   0.006208        140        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.636      0.287      0.295      0.112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/20      3.68G    0.06147     0.0496   0.006012        188        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.593       0.26      0.259      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/20      3.68G    0.06065    0.04926   0.005712        158        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844       0.65      0.273      0.287      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/20      3.68G    0.05964    0.04858   0.005462        136        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.394      0.308      0.312      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/20      3.68G     0.0592    0.04806   0.005338        138        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.421      0.306      0.326      0.128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/20      3.68G     0.0587    0.04828   0.005214        111        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.406      0.302      0.322      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/20      3.68G    0.05801    0.04744   0.005046        176        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.443      0.329      0.351      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/20      3.68G    0.05779    0.04713   0.004948        128        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.685      0.305      0.328      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/20      3.68G    0.05697     0.0471   0.004768         95        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.438      0.323      0.337      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/20      3.68G    0.05655    0.04668   0.004512        111        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.443      0.325      0.345       0.14\n",
      "\n",
      "21 epochs completed in 0.765 hours.\n",
      "Optimizer stripped from runs/train/exp20/weights/last.pt, 14.4MB\n",
      "Optimizer stripped from runs/train/exp20/weights/best.pt, 14.4MB\n",
      "\n",
      "Validating runs/train/exp20/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1257      10844      0.449      0.326      0.352      0.139\n",
      "                person       1257       5405       0.54      0.381      0.409      0.139\n",
      "               bicycle       1257        419      0.571      0.356      0.352     0.0976\n",
      "                   car       1257       5007      0.686      0.567      0.618      0.317\n",
      "                   dog       1257         13          0          0     0.0287    0.00477\n",
      "Results saved to \u001b[1mruns/train/exp20\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "img_size = 640  # Image size\n",
    "batch_size = 32  # Batch size\n",
    "epochs = 21  # Number of epochs\n",
    "data_yaml_path = '/home/deepaksr/project/project_assignment2/adasv1_notebooks/rgb.yaml'  # Path to your dataset YAML file\n",
    "weights = 'yolov5s.pt'  # Pre-trained weights\n",
    "device = '0,1,2,3'  # Use '0' for first GPU\n",
    "\n",
    "!python train.py --img {img_size} --batch {batch_size} --epochs {epochs} --data {data_yaml_path} --weights {weights} --device {device}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/home/deepaksr/project/project_assignment2/adas_v1/yolov5/runs/train/exp20/weights/best.pt'], source=/home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=1, view_img=False, save_txt=True, save_format=0, save_csv=False, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 🚀 v7.0-371-g6629839d Python-3.8.20 torch-2.4.1+cu121 CUDA:1 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00001.jpg: 576x640 1 person, 9 cars, 29.0ms\n",
      "image 2/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00002.jpg: 576x640 1 person, 10 cars, 5.8ms\n",
      "image 3/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00003.jpg: 576x640 1 person, 8 cars, 5.3ms\n",
      "image 4/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00004.jpg: 576x640 1 person, 6 cars, 5.5ms\n",
      "image 5/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00005.jpg: 576x640 1 person, 8 cars, 5.5ms\n",
      "image 6/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00006.jpg: 576x640 1 person, 9 cars, 5.4ms\n",
      "image 7/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00007.jpg: 576x640 8 cars, 5.1ms\n",
      "image 8/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00008.jpg: 576x640 1 person, 7 cars, 5.2ms\n",
      "image 9/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00009.jpg: 576x640 9 cars, 5.2ms\n",
      "image 10/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00010.jpg: 576x640 8 cars, 5.2ms\n",
      "image 11/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00011.jpg: 576x640 7 cars, 5.3ms\n",
      "image 12/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00012.jpg: 576x640 6 cars, 5.3ms\n",
      "image 13/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00013.jpg: 576x640 6 cars, 5.1ms\n",
      "image 14/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00014.jpg: 576x640 7 cars, 5.2ms\n",
      "image 15/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00015.jpg: 576x640 8 cars, 5.2ms\n",
      "image 16/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00016.jpg: 576x640 6 cars, 5.2ms\n",
      "image 17/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00017.jpg: 576x640 8 cars, 5.3ms\n",
      "image 18/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00018.jpg: 576x640 8 cars, 5.3ms\n",
      "image 19/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00019.jpg: 576x640 7 cars, 5.3ms\n",
      "image 20/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00020.jpg: 576x640 8 cars, 5.3ms\n",
      "image 21/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00021.jpg: 576x640 8 cars, 5.2ms\n",
      "image 22/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00022.jpg: 576x640 10 cars, 5.1ms\n",
      "image 23/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00023.jpg: 576x640 9 cars, 5.2ms\n",
      "image 24/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00024.jpg: 576x640 8 cars, 5.2ms\n",
      "image 25/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00025.jpg: 576x640 7 cars, 5.2ms\n",
      "image 26/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00026.jpg: 576x640 9 cars, 5.3ms\n",
      "image 27/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00027.jpg: 576x640 8 cars, 6.2ms\n",
      "image 28/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00028.jpg: 576x640 7 cars, 5.2ms\n",
      "image 29/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00029.jpg: 576x640 9 cars, 5.2ms\n",
      "image 30/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00030.jpg: 576x640 8 cars, 5.4ms\n",
      "image 31/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00031.jpg: 576x640 8 cars, 5.2ms\n",
      "image 32/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00032.jpg: 576x640 10 cars, 5.3ms\n",
      "image 33/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00033.jpg: 576x640 10 cars, 5.2ms\n",
      "image 34/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00034.jpg: 576x640 11 cars, 5.2ms\n",
      "image 35/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00035.jpg: 576x640 11 cars, 5.2ms\n",
      "image 36/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00036.jpg: 576x640 10 cars, 5.5ms\n",
      "image 37/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00037.jpg: 576x640 12 cars, 5.4ms\n",
      "image 38/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00038.jpg: 576x640 10 cars, 5.4ms\n",
      "image 39/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00039.jpg: 576x640 9 cars, 5.3ms\n",
      "image 40/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00040.jpg: 576x640 10 cars, 5.2ms\n",
      "image 41/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00041.jpg: 576x640 10 cars, 5.4ms\n",
      "image 42/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00042.jpg: 576x640 10 cars, 5.4ms\n",
      "image 43/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00043.jpg: 576x640 9 cars, 5.1ms\n",
      "image 44/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00044.jpg: 576x640 9 cars, 5.2ms\n",
      "image 45/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00045.jpg: 576x640 9 cars, 5.2ms\n",
      "image 46/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00046.jpg: 576x640 8 cars, 5.2ms\n",
      "image 47/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00047.jpg: 576x640 8 cars, 5.6ms\n",
      "image 48/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00048.jpg: 576x640 9 cars, 5.2ms\n",
      "image 49/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00049.jpg: 576x640 8 cars, 5.2ms\n",
      "image 50/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00050.jpg: 576x640 8 cars, 5.5ms\n",
      "image 51/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00051.jpg: 576x640 7 cars, 5.5ms\n",
      "image 52/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00052.jpg: 576x640 8 cars, 5.2ms\n",
      "image 53/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00053.jpg: 576x640 5 cars, 5.2ms\n",
      "image 54/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00054.jpg: 576x640 6 cars, 5.3ms\n",
      "image 55/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00055.jpg: 576x640 6 cars, 5.1ms\n",
      "image 56/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00056.jpg: 576x640 4 cars, 5.2ms\n",
      "image 57/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00057.jpg: 576x640 6 cars, 5.4ms\n",
      "image 58/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00058.jpg: 576x640 6 cars, 5.3ms\n",
      "image 59/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00059.jpg: 576x640 6 cars, 5.6ms\n",
      "image 60/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00060.jpg: 576x640 6 cars, 5.4ms\n",
      "image 61/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00061.jpg: 576x640 6 cars, 5.2ms\n",
      "image 62/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00062.jpg: 576x640 6 cars, 5.2ms\n",
      "image 63/4195 /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_00063.jpg: 576x640 6 cars, 5.2ms\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"detect.py\", line 437, in <module>\n",
      "    main(opt)\n",
      "  File \"detect.py\", line 432, in main\n",
      "    run(**vars(opt))\n",
      "  File \"/home/deepaksr/miniconda3/envs/yolov5/lib/python3.8/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"detect.py\", line 272, in run\n",
      "    f.write((\"%g \" * len(line)).rstrip() % line + \"\\n\")\n",
      "OSError: [Errno 28] No space left on device\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights /home/deepaksr/project/project_assignment2/adas_v1/yolov5/runs/train/exp20/weights/best.pt --img 640 --conf 0.25 --source /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images --device 1 --save-txt --save-conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/deepaksr/project/project_assignment2/adasv1_notebooks/rgb.yaml, weights=['/home/deepaksr/project/project_assignment2/adas_v1/yolov5/runs/train/exp20/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=test, device=1, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v7.0-371-g6629839d Python-3.8.20 torch-2.4.1+cu121 CUDA:1 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mWARNING ⚠️ /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_02466.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mWARNING ⚠️ /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/images/FLIR_video_03372.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /home/deepaksr/project/project_assignment2/adas_v1/FLIR_ADAS_1_3/video/rgbwithlabels/labels.cache\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4195      36949      0.318      0.152      0.135     0.0449\n",
      "                person       4195      21797      0.183     0.0605     0.0325    0.00671\n",
      "               bicycle       4195       1179      0.318      0.109     0.0891     0.0193\n",
      "                   car       4195      13973      0.454      0.288      0.284      0.109\n",
      "Speed: 0.2ms pre-process, 3.0ms inference, 1.9ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python val.py --weights /home/deepaksr/project/project_assignment2/adas_v1/yolov5/runs/train/exp20/weights/best.pt --data /home/deepaksr/project/project_assignment2/adasv1_notebooks/rgb.yaml --img 640 --task test --device 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
